{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymxatB5WYxlL"
   },
   "source": [
    "# Transformer 실습\n",
    "\n",
    "이번 실습에서는 감정 분석 task에 RNN 대신 Transformer를 구현하여 적용해 볼 것입니다.\n",
    "Library import나 dataloader 생성은 RNN 실습 때와 똑같기 때문에 설명은 넘어가도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1X7RM2du1zcr",
    "outputId": "d55cac8d-975b-4f67-a2f0-6b09565650c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (3.1.0)\n",
      "Requirement already satisfied: sacremoses in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (0.1.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from datasets) (1.24.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from datasets) (3.10.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from datasets) (0.27.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from sacremoses) (2024.11.6)\n",
      "Requirement already satisfied: click in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from sacremoses) (8.1.8)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from sacremoses) (1.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from aiohttp->datasets) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/torch-nightly/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/kelly/.cache/torch/hub/huggingface_pytorch-transformers_main\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizerFast\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "ds = load_dataset(\"stanfordnlp/imdb\")\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased')\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "  max_len = 400\n",
    "  texts, labels = [], []\n",
    "  for row in batch:\n",
    "    labels.append(row['label'])\n",
    "    texts.append(row['text'])\n",
    "\n",
    "  texts = torch.LongTensor(tokenizer(texts, padding=True, truncation=True, max_length=max_len).input_ids)\n",
    "  labels = torch.LongTensor(labels)\n",
    "\n",
    "  return texts, labels\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    ds['train'], batch_size=64, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    ds['test'], batch_size=64, shuffle=False, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, dff, n_heads, n_layers, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerLayer(input_dim, d_model, dff, n_heads, dropout_rate)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-FshZcTZBQ2"
   },
   "source": [
    "## Self-attention\n",
    "\n",
    "이번에는 self-attention을 구현해보겠습니다.\n",
    "Self-attention은 shape이 (B, S, D)인 embedding이 들어왔을 때 attention을 적용하여 새로운 representation을 만들어내는 module입니다.\n",
    "여기서 B는 batch size, S는 sequence length, D는 embedding 차원입니다.\n",
    "구현은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MBlMVMZcRAxv"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "  def __init__(self, input_dim, d_model):\n",
    "    super().__init__()\n",
    "\n",
    "    self.input_dim = input_dim\n",
    "    self.d_model = d_model\n",
    "\n",
    "    self.wq = nn.Linear(input_dim, d_model)\n",
    "    self.wk = nn.Linear(input_dim, d_model)\n",
    "    self.wv = nn.Linear(input_dim, d_model)\n",
    "    self.dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "    self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "  def forward(self, x, mask):\n",
    "    q, k, v = self.wq(x), self.wk(x), self.wv(x)\n",
    "    score = torch.matmul(q, k.transpose(-1, -2)) # (B, S, D) * (B, D, S) = (B, S, S)\n",
    "    score = score / sqrt(self.d_model)\n",
    "\n",
    "    if mask is not None:\n",
    "      score = score + (mask * -1e9)\n",
    "\n",
    "    score = self.softmax(score)\n",
    "    result = torch.matmul(score, v)\n",
    "    result = self.dense(result)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-S0vMp85ZRNO"
   },
   "source": [
    "대부분은 Transformer 챕터에서 배운 수식들을 그대로 구현한 것에 불과합니다.\n",
    "차이점은 `mask`의 존재여부입니다.\n",
    "이전 챕터에서 우리는 가변적인 text data들에 padding token을 붙여 하나의 matrix로 만든 방법을 배웠습니다.\n",
    "실제 attention 계산에서는 이를 무시해주기 위해 mask를 만들어 제공해주게 됩니다.\n",
    "여기서 mask의 shape은 (B, S, 1)로, 만약 `mask[i, j] = True`이면 그 변수는 padding token에 해당한다는 뜻입니다.\n",
    "이러한 값들을 무시해주는 방법은 shape이 (B, S, S)인 `score`가 있을 때(수업에서 배운 $A$와 동일) `score[i, j]`에 아주 작은 값을 더해주면 됩니다. 아주 작은 값은 예를 들어 `-1000..00 = -1e9` 같은 것이 있습니다.\n",
    "이렇게 작은 값을 더해주고 나면 softmax를 거쳤을 때 0에 가까워지기 때문에 weighted sum 과정에서 padding token에 해당하는 `v` 값들을 무시할 수 있게 됩니다.\n",
    "\n",
    "다음은 self-attention과 feed-forward layer를 구현한 모습입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[Mycode] MHA\n",
    "Q,K,V 분리 및 분할\n",
    "QK^T/rootD' 계산 후 softmax 로 정규화\n",
    "결과 값 병합하고 다시 integration\n",
    "\n",
    "- [ ]  Multi-head attention(MHA) 구현\n",
    "    - Self-attention module을 MHA로 확장해주시면 됩니다. 여기서 MHA는 다음과 같이 구현합니다.\n",
    "        1. 기존의 $W_q, W_k, W_v$를 사용하여 $Q, K, V$를 생성합니다. 이 부분은 코드 수정이 필요 없습니다.\n",
    "        2. $Q, K, V \\in \\mathbb{R}^{S \\times D}$가 있을 때, 이를 $Q, K, V \\in \\mathbb{R}^{S \\times H \\times D’}$으로 reshape 해줍니다. 여기서 $H$는 `n_heads`라는 인자로 받아야 하고, $D$가 $H$로 나눠 떨어지는 값이여야 하는 제약 조건이 필요합니다. $D = H \\times D’$입니다.\n",
    "        3. $Q, K, V$를 $Q, K, V \\in \\mathbb{R}^{H \\times S \\times D’}$의 shape으로 transpose해줍니다.\n",
    "        4. $A = QK^T/\\sqrt{D'} \\in \\mathbb{R}^{H \\times S \\times S}$를 기존의 self-attention과 똑같이 계산합니다. 이 부분은 코드 수정이 필요 없습니다.\n",
    "        5. Mask를 더합니다. 기존과 $A$의 shape이 달라졌기 때문에 dimension을 어떻게 맞춰줘야할지 생각해줘야 합니다.\n",
    "        6. $\\hat{x} = \\textrm{Softmax}(A)V \\in \\mathbb{R}^{H \\times S \\times D'}$를 계산해주고 transpose와 reshape을 통해 $\\hat{x} \\in \\mathbb{R}^{S \\times D}$의 shape으로 다시 만들어줍니다.\n",
    "        7. 기존과 똑같이 $\\hat{x} = \\hat{x} W_o$를 곱해줘서 마무리 해줍니다. 이 또한 코드 수정이 필요 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from math import sqrt\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, n_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        assert d_model % n_heads == 0, \"d_model must be divisible by n_heads\"\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.depth = d_model // n_heads\n",
    "\n",
    "        # Linear layers for Q, K, V\n",
    "        self.wq = nn.Linear(input_dim, d_model)\n",
    "        self.wk = nn.Linear(input_dim, d_model)\n",
    "        self.wv = nn.Linear(input_dim, d_model)\n",
    "\n",
    "        # Output linear layer\n",
    "        self.dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        # Compute Q, K, V\n",
    "        Q = self.wq(x)  # (B, S, D)\n",
    "        K = self.wk(x)  # (B, S, D)\n",
    "        V = self.wv(x)  # (B, S, D)\n",
    "\n",
    "        # Reshape to (B, H, S, D')\n",
    "        Q = Q.view(batch_size, seq_len, self.n_heads, self.depth).transpose(1, 2)\n",
    "        K = K.view(batch_size, seq_len, self.n_heads, self.depth).transpose(1, 2)\n",
    "        V = V.view(batch_size, seq_len, self.n_heads, self.depth).transpose(1, 2)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / sqrt(self.depth)  # (B, H, S, S)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)  # Adjust mask shape to (B, 1, 1, S)\n",
    "            scores += mask * -1e9\n",
    "\n",
    "        attention_weights = F.softmax(scores, dim=-1)  # (B, H, S, S)\n",
    "        attention_output = torch.matmul(attention_weights, V)  # (B, H, S, D')\n",
    "\n",
    "        # Concatenate heads and reshape to (B, S, D)\n",
    "        attention_output = attention_output.transpose(1, 2).contiguous()\n",
    "        attention_output = attention_output.view(batch_size, seq_len, self.d_model)\n",
    "\n",
    "        # Apply final linear layer\n",
    "        output = self.dense(attention_output)  # (B, S, D)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[MyCode] TransformerLayer\n",
    "MultiHeadAttention 적용\n",
    "기존 SelfAttention 모듈을 MultiHeadAttention으로 확장 => 입력 특징을 여러 하위 공간으로 분할하여 더 복잡한 관계를 학습\n",
    "Feed-Forward Network (FFN)\n",
    "d_model → dff → d_model 변환을 통해 내부 표현 공간을 확장\n",
    "Layer Normalization과 Dropout을 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VZHPCn9AS5Gp"
   },
   "outputs": [],
   "source": [
    "class TransformerLayer(nn.Module):\n",
    "  def __init__(self, input_dim, d_model, dff, n_heads, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(input_dim, d_model, n_heads)\n",
    "\n",
    "    # self.input_dim = input_dim\n",
    "    # self.d_model = d_model\n",
    "    # self.dff = dff\n",
    "    # self.sa = SelfAttention(input_dim, d_model)\n",
    "\n",
    "    self.ffn = nn.Sequential(\n",
    "      nn.Linear(d_model, dff),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(dff, d_model)\n",
    "    )\n",
    " #  Layer Normalization, Dropout, Residual Connection\n",
    "    self.layernorm1 = nn.LayerNorm(d_model)\n",
    "    self.layernorm2 = nn.LayerNorm(d_model)\n",
    "    self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "  def forward(self, x, mask):\n",
    "        # Multi-Head Attention\n",
    "        x1 = self.mha(x, mask)\n",
    "        x1 = self.dropout(x1)\n",
    "        x1 = self.layernorm1(x1 + x)  # Residual connection\n",
    "\n",
    "        # Feed-Forward Network#\n",
    "        x2 = self.ffn(x1)\n",
    "        x2 = self.dropout(x2)\n",
    "        x2 = self.layernorm2(x2 + x1)  # Residual connection\n",
    "\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "대부분은 Transformer 챕터에서 배운 수식들을 그대로 구현한 것에 불과합니다. 차이점은 mask의 존재여부입니다. 이전 챕터에서 우리는 가변적인 text data들에 padding token을 붙여 하나의 matrix로 만든 방법을 배웠습니다. 실제 attention 계산에서는 이를 무시해주기 위해 mask를 만들어 제공해주게 됩니다. 여기서 mask의 shape은 (B, S, 1)로, 만약 mask[i, j] = True이면 그 변수는 padding token에 해당한다는 뜻입니다. 이러한 값들을 무시해주는 방법은 shape이 (B, S, S)인 score가 있을 때(수업에서 배운 \n",
    "와 동일) score[i, j]에 아주 작은 값을 더해주면 됩니다. 아주 작은 값은 예를 들어 -1000..00 = -1e9 같은 것이 있습니다. 이렇게 작은 값을 더해주고 나면 softmax를 거쳤을 때 0에 가까워지기 때문에 weighted sum 과정에서 padding token에 해당하는 v 값들을 무시할 수 있게 됩니다.\n",
    "\n",
    "다음은 self-attention과 feed-forward layer를 구현한 모습입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_xC9BQJaU4q"
   },
   "source": [
    "보시다시피 self-attention의 구현이 어렵지, Transformer layer 하나 구현하는 것은 수업 때 다룬 그림과 크게 구분되지 않는다는 점을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3VYrqTJagS1"
   },
   "source": [
    "## Positional encoding\n",
    "\n",
    "이번에는 positional encoding을 구현합니다. Positional encoding의 식은 다음과 같습니다:\n",
    "$$\n",
    "\\begin{align*} PE_{pos, 2i} &= \\sin\\left( \\frac{pos}{10000^{2i/D}} \\right), \\\\ PE_{pos, 2i+1} &= \\cos\\left( \\frac{pos}{10000^{2i/D}} \\right).\\end{align*}\n",
    "$$\n",
    "\n",
    "이를 Numpy로 구현하여 PyTorch tensor로 변환한 모습은 다음과 같습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uf_jMQWDUR79",
    "outputId": "534712be-1522-4d32-81b7-87f50a6f1f2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 400, 256])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, None], np.arange(d_model)[None, :], d_model)\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    pos_encoding = angle_rads[None, ...]\n",
    "\n",
    "    return torch.FloatTensor(pos_encoding)\n",
    "\n",
    "\n",
    "max_len = 400\n",
    "print(positional_encoding(max_len, 256).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5unoDcBva3eN"
   },
   "source": [
    "Positional encoding은 `angle_rads`를 구현하는 과정에서 모두 구현이 되었습니다. 여기서 `angle_rads`의 shape은 (S, D)입니다.\n",
    "우리는 일반적으로 batch로 주어지는 shape이 (B, S, D)인 tensor를 다루기 때문에 마지막에 None을 활용하여 shape을 (1, S, D)로 바꿔주게됩니다.\n",
    "\n",
    "위에서 구현한 `TransformerLayer`와 positional encoding을 모두 합친 모습은 다음과 같습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[MyCode]\n",
    "Mask 생성 시 to(x.device)를 추가해 입력 데이터와 동일한 장치(CPU/GPU)로 이동하도록 수정->> 아래 학습 오류 부분 수정을 위해 (CPU 관련 에러로 추가)\n",
    "\n",
    "classification에서 CLS 토큰(x[:, 0])을 사용해 최종 분류 결과 계산."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8MaiCGh8TsDH"
   },
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_layers, dff, n_heads):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.n_layers = n_layers\n",
    "        self.dff = dff\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = nn.parameter.Parameter(positional_encoding(max_len, d_model), requires_grad=False)\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerLayer(d_model, d_model, dff, n_heads) for _ in range(n_layers)\n",
    "        ])\n",
    "        self.classification = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Mask 생성\n",
    "        mask = (x == tokenizer.pad_token_id).unsqueeze(1).to(x.device)  # mask 생성 및 이동\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        # Embedding 및 Positional Encoding 추가ㅠ\n",
    "        x = self.embedding(x)  # (B, S, D)\n",
    "        x = x * sqrt(self.d_model)\n",
    "        x = x + self.pos_encoding[:, :seq_len]\n",
    "\n",
    "        # Transformer 레이어 통과\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "\n",
    "        # 첫 번째 토큰의 벡터 사용 (CLS 토큰)\n",
    "        x = x[:, 0]  # (B, D)\n",
    "        x = self.classification(x)  # (B, 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "#model = TextClassifier(len(tokenizer), 32, 2, 32)\n",
    "model = TextClassifier(len(tokenizer), d_model=32, n_layers=2, dff=32, n_heads=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXpjPWHjbUK8"
   },
   "source": [
    "기존과 다른 점들은 다음과 같습니다:\n",
    "1. `nn.ModuleList`를 사용하여 여러 layer의 구현을 쉽게 하였습니다.\n",
    "2. Embedding, positional encoding, transformer layer를 거치고 난 후 마지막 label을 예측하기 위해 사용한 값은 `x[:, 0]`입니다. 기존의 RNN에서는 padding token을 제외한 마지막 token에 해당하는 representation을 사용한 것과 다릅니다. 이렇게 사용할 수 있는 이유는 attention 과정을 보시면 첫 번째 token에 대한 representation은 이후의 모든 token의 영향을 받습니다. 즉, 첫 번째 token 또한 전체 문장을 대변하는 의미를 가지고 있다고 할 수 있습니다. 그래서 일반적으로 Transformer를 text 분류에 사용할 때는 이와 같은 방식으로 구현됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDq05OlAb2lB"
   },
   "source": [
    "## 학습\n",
    "\n",
    "학습하는 코드는 기존 실습들과 동일하기 때문에 마지막 결과만 살펴보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHVVsWBPQmnv",
    "outputId": "64b5790f-7649-4a47-95f8-bebe158aba4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정 및 모델 생성\n",
    "input_dim = 32   # 입력 임베딩 차원\n",
    "d_model = 128    # 모델의 차원\n",
    "dff = 256        # FFN 내부 차원\n",
    "n_heads = 4      # Multi-Head Attention 헤드 수\n",
    "n_layers = 5     # Transformer 레이어 수\n",
    "dropout_rate = 0.1\n",
    "\n",
    "# 5-layer 4-head Transformer 생성\n",
    "model = Transformer(input_dim, d_model, dff, n_heads, n_layers, dropout_rate).to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "lr = 0.001\n",
    "model = model.to('mps')\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def accuracy(model, dataloader):\n",
    "  cnt = 0\n",
    "  acc = 0\n",
    "\n",
    "  for data in dataloader:\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to('mps'), labels.to('mps')\n",
    "\n",
    "    preds = model(inputs)\n",
    "    # preds = torch.argmax(preds, dim=-1)\n",
    "    preds = (preds > 0).long()[..., 0]\n",
    "\n",
    "    cnt += labels.shape[0]\n",
    "    acc += (labels == preds).sum().item()\n",
    "\n",
    "  return acc / cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r88BALxO1zc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Loss: 360.5684\n",
      "=========> Train acc: 0.500 | Test acc: 0.500\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "model = TextClassifier(len(tokenizer), d_model=32, n_layers=2, dff=32, n_heads=4).to('mps')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0.0\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to('mps'), labels.to('mps').float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(inputs)  # mask는 내부에서 생성\n",
    "        loss = loss_fn(preds[..., 0], labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs} | Loss: {total_loss:.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        train_acc = accuracy(model, train_loader)\n",
    "        test_acc = accuracy(model, test_loader)\n",
    "        print(f\"=========> Train acc: {train_acc:.3f} | Test acc: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "al_b56TYRILq",
    "outputId": "90a56264-4ef3-4def-e7b7-df4b5cd3c305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train Loss: 228.05881744623184\n",
      "=========> Train acc: 0.770 | Test acc: 0.745\n",
      "Epoch   1 | Train Loss: 181.79184779524803\n",
      "=========> Train acc: 0.818 | Test acc: 0.776\n",
      "Epoch   2 | Train Loss: 161.0439212024212\n",
      "=========> Train acc: 0.847 | Test acc: 0.786\n",
      "Epoch   3 | Train Loss: 144.77784506976604\n",
      "=========> Train acc: 0.866 | Test acc: 0.798\n",
      "Epoch   4 | Train Loss: 127.65684458613396\n",
      "=========> Train acc: 0.892 | Test acc: 0.800\n",
      "Epoch   5 | Train Loss: 113.74214302748442\n",
      "=========> Train acc: 0.907 | Test acc: 0.804\n",
      "Epoch   6 | Train Loss: 101.79052671045065\n",
      "=========> Train acc: 0.916 | Test acc: 0.799\n",
      "Epoch   7 | Train Loss: 90.75403520092368\n",
      "=========> Train acc: 0.937 | Test acc: 0.809\n",
      "Epoch   8 | Train Loss: 77.53205958008766\n",
      "=========> Train acc: 0.945 | Test acc: 0.808\n",
      "Epoch   9 | Train Loss: 68.24311332032084\n",
      "=========> Train acc: 0.957 | Test acc: 0.804\n",
      "Epoch  10 | Train Loss: 58.22225522249937\n",
      "=========> Train acc: 0.964 | Test acc: 0.801\n",
      "Epoch  11 | Train Loss: 51.82508478872478\n",
      "=========> Train acc: 0.964 | Test acc: 0.798\n",
      "Epoch  12 | Train Loss: 44.73537188582122\n",
      "=========> Train acc: 0.975 | Test acc: 0.800\n",
      "Epoch  13 | Train Loss: 36.328937944956124\n",
      "=========> Train acc: 0.970 | Test acc: 0.795\n",
      "Epoch  14 | Train Loss: 31.212427048478276\n",
      "=========> Train acc: 0.984 | Test acc: 0.799\n",
      "Epoch  15 | Train Loss: 27.794022045098245\n",
      "=========> Train acc: 0.986 | Test acc: 0.798\n",
      "Epoch  16 | Train Loss: 24.51000529155135\n",
      "=========> Train acc: 0.988 | Test acc: 0.798\n",
      "Epoch  17 | Train Loss: 25.019716920796782\n",
      "=========> Train acc: 0.988 | Test acc: 0.795\n",
      "Epoch  18 | Train Loss: 18.76576793473214\n",
      "=========> Train acc: 0.989 | Test acc: 0.794\n",
      "Epoch  19 | Train Loss: 19.29518177837599\n",
      "=========> Train acc: 0.992 | Test acc: 0.798\n",
      "Epoch  20 | Train Loss: 16.6582816374721\n",
      "=========> Train acc: 0.992 | Test acc: 0.802\n",
      "Epoch  21 | Train Loss: 17.27638038888108\n",
      "=========> Train acc: 0.991 | Test acc: 0.791\n",
      "Epoch  22 | Train Loss: 15.25645094725769\n",
      "=========> Train acc: 0.989 | Test acc: 0.797\n",
      "Epoch  23 | Train Loss: 14.676565335481428\n",
      "=========> Train acc: 0.995 | Test acc: 0.795\n",
      "Epoch  24 | Train Loss: 11.922925418621162\n",
      "=========> Train acc: 0.994 | Test acc: 0.792\n",
      "Epoch  25 | Train Loss: 12.693496667896397\n",
      "=========> Train acc: 0.988 | Test acc: 0.797\n",
      "Epoch  26 | Train Loss: 11.326061181141995\n",
      "=========> Train acc: 0.972 | Test acc: 0.789\n",
      "Epoch  27 | Train Loss: 12.779942307330202\n",
      "=========> Train acc: 0.996 | Test acc: 0.795\n",
      "Epoch  28 | Train Loss: 10.617993225852842\n",
      "=========> Train acc: 0.993 | Test acc: 0.800\n",
      "Epoch  29 | Train Loss: 9.673813316738233\n",
      "=========> Train acc: 0.996 | Test acc: 0.794\n",
      "Epoch  30 | Train Loss: 11.522750682837795\n",
      "=========> Train acc: 0.996 | Test acc: 0.794\n",
      "Epoch  31 | Train Loss: 7.840653722785646\n",
      "=========> Train acc: 0.994 | Test acc: 0.792\n",
      "Epoch  32 | Train Loss: 12.104161699942779\n",
      "=========> Train acc: 0.995 | Test acc: 0.793\n",
      "Epoch  33 | Train Loss: 8.25330251167179\n",
      "=========> Train acc: 0.985 | Test acc: 0.793\n",
      "Epoch  34 | Train Loss: 10.357778827659786\n",
      "=========> Train acc: 0.997 | Test acc: 0.796\n",
      "Epoch  35 | Train Loss: 9.444769158624695\n",
      "=========> Train acc: 0.995 | Test acc: 0.794\n",
      "Epoch  36 | Train Loss: 8.166781437234022\n",
      "=========> Train acc: 0.996 | Test acc: 0.792\n",
      "Epoch  37 | Train Loss: 9.650583731883671\n",
      "=========> Train acc: 0.997 | Test acc: 0.795\n",
      "Epoch  38 | Train Loss: 7.418147705044248\n",
      "=========> Train acc: 0.996 | Test acc: 0.794\n",
      "Epoch  39 | Train Loss: 9.709464895306155\n",
      "=========> Train acc: 0.997 | Test acc: 0.794\n",
      "Epoch  40 | Train Loss: 7.829162544643623\n",
      "=========> Train acc: 0.996 | Test acc: 0.792\n",
      "Epoch  41 | Train Loss: 6.924684327503201\n",
      "=========> Train acc: 0.995 | Test acc: 0.786\n",
      "Epoch  42 | Train Loss: 7.91478517052019\n",
      "=========> Train acc: 0.996 | Test acc: 0.792\n",
      "Epoch  43 | Train Loss: 7.378424593654927\n",
      "=========> Train acc: 0.998 | Test acc: 0.793\n",
      "Epoch  44 | Train Loss: 6.822792663617292\n",
      "=========> Train acc: 0.996 | Test acc: 0.795\n",
      "Epoch  45 | Train Loss: 6.635453788730956\n",
      "=========> Train acc: 0.998 | Test acc: 0.795\n",
      "Epoch  46 | Train Loss: 6.294900413195137\n",
      "=========> Train acc: 0.996 | Test acc: 0.798\n",
      "Epoch  47 | Train Loss: 7.062853217605152\n",
      "=========> Train acc: 0.994 | Test acc: 0.793\n",
      "Epoch  48 | Train Loss: 6.103620611334918\n",
      "=========> Train acc: 0.998 | Test acc: 0.797\n",
      "Epoch  49 | Train Loss: 5.912332823994802\n",
      "=========> Train acc: 0.995 | Test acc: 0.794\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  total_loss = 0.\n",
    "  model.train()\n",
    "  for data in train_loader:\n",
    "    model.zero_grad()\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to('cuda'), labels.to('cuda').float()\n",
    "\n",
    "    preds = model(inputs)[..., 0]\n",
    "    loss = loss_fn(preds, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "\n",
    "  print(f\"Epoch {epoch:3d} | Train Loss: {total_loss}\")\n",
    "\n",
    "  with torch.no_grad():\n",
    "    model.eval()\n",
    "    train_acc = accuracy(model, train_loader)\n",
    "    test_acc = accuracy(model, test_loader)\n",
    "    print(f\"=========> Train acc: {train_acc:.3f} | Test acc: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqZays2yb8Ja"
   },
   "source": [
    "학습이 안정적으로 진행되며 RNN보다 빨리 수렴하는 것을 확인할 수 있습니다.\n",
    "하지만 test 정확도가 RNN보다 낮은 것을 보았을 때, overfitting에 취약하다는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAXB6GgIQy1S"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
