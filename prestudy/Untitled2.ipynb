{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a51ebe1-9878-4a7c-9639-b011d96fcd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# neural network \n",
    "import torch.nn as nn\n",
    "# 최적화 - 함수에 대한 최대 혹은 최저값의 변수들은 찾는 것 \n",
    "import torch.optim as optim\n",
    "#ann이라는 모델을 다를 때 f(ax+b) 이미지 처리\n",
    "import torchvision\n",
    "#전처리를 위한 lib\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ac24d2-9803-4d5f-9024-d46d49f83199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 9912422/9912422 [00:05<00:00, 1716543.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 28881/28881 [00:00<00:00, 140027.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1648877/1648877 [00:01<00:00, 1271244.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 4542/4542 [00:00<00:00, 892630.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#데이터셋 전처리\n",
    "# 학습을 원활히 하기 위한 과정으로 transform 여러 변환을 순차적으로 적용, \n",
    "# 평균이 0.5 표준편차 0.5로 이미지 정규화\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# MNIST 데이터셋로드\n",
    "# batch_size64개로 쪼개 순서대로 쪼개면 순서관계가 있는경우 의존성이 있을수 있어 학습이 잘되지 않을수 있어 섞는다.\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b59684c0-f630-4e49-8afe-f3ad98d888de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5,), std=(0.5,))\n",
       "           )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84177542-9401-4e9c-8d38-6a57fd2c5aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x16645db50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f49275-9edf-4c49-a896-1d79eb4cfd4a",
   "metadata": {},
   "source": [
    "딥러닝 모델을 만드는 과정\n",
    "클래스 정의 nn모듈 상속받아야 한다. \n",
    "딥러닝 모델을 만들기 위한 기본기능을 사전에 가져온다.\n",
    "1. 생성자 init함수 구성 - 각각의 layer정의\n",
    "2. layer 구성 fc 는 fully connected layer - layer간의 모두 연결되어 있을때 fc\n",
    "3. 파라미터로 모델 설정 nn.linear - ann모델을 만들기 위한 함수 layer에서 입력과 출력 정의해야 한다.\n",
    "4. fc1의 두번째 파라미터 fc2의 첫번째 파라미터와 연결, fc2의 두번째 파라미터 fc3의 첫번째 파라미터와 연결 0-9까지 예측하기 위해 마지막 fc3의 두번째 파라미터는 10개의 퍼셉트론\n",
    "5. 28*28은 mnist의 데이터 크기 사진을 받아서 처리하고 최종 10개로 예측\n",
    "6. forward함수정의 - 자동적으로 layer간의 연결관계 정의. 이미지 데이터가 들어오는데 fully connected layer는 1차원데이터를 받는 layer이므로 우선 1차원으로 변환 view함수를 통해 차원변환. -1은 2차원을 기준으로 데이터를 알아서 정의하라는 의미.\n",
    "7. 데이터가들어올때 batch단위인 64개 쪼개서 들어오는데 학습을 위한 데이터 1*64 데이터차원을지정해주고 batch의 차원을 알아서 정의한다.\n",
    "8. torch.relu(self.fc1) - 입력레이어에 전달한다음 relu저장 x 64*10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48fa5b80-d43b-47ce-b47c-1f35492fd343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128) #입력층에서 은닉층으로\n",
    "        self.fc2 = nn.Linear(128, 64)    #은닉층에서 은닉층으로\n",
    "        self.fc3 = nn.Linear(64, 10)     #은닉층에서 출력층으로\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8ca8f70-cfd6-40f5-8bc8-f853cabf819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch 100] loss: 1.326\n",
      "[Epoch 1, Batch 200] loss: 0.450\n",
      "[Epoch 1, Batch 300] loss: 0.385\n",
      "[Epoch 1, Batch 400] loss: 0.353\n",
      "[Epoch 1, Batch 500] loss: 0.310\n",
      "[Epoch 1, Batch 600] loss: 0.300\n",
      "[Epoch 1, Batch 700] loss: 0.274\n",
      "[Epoch 1, Batch 800] loss: 0.251\n",
      "[Epoch 1, Batch 900] loss: 0.240\n",
      "[Epoch 2, Batch 100] loss: 0.199\n",
      "[Epoch 2, Batch 200] loss: 0.194\n",
      "[Epoch 2, Batch 300] loss: 0.180\n",
      "[Epoch 2, Batch 400] loss: 0.197\n",
      "[Epoch 2, Batch 500] loss: 0.160\n",
      "[Epoch 2, Batch 600] loss: 0.172\n",
      "[Epoch 2, Batch 700] loss: 0.164\n",
      "[Epoch 2, Batch 800] loss: 0.154\n",
      "[Epoch 2, Batch 900] loss: 0.175\n",
      "[Epoch 3, Batch 100] loss: 0.129\n",
      "[Epoch 3, Batch 200] loss: 0.138\n",
      "[Epoch 3, Batch 300] loss: 0.137\n",
      "[Epoch 3, Batch 400] loss: 0.130\n",
      "[Epoch 3, Batch 500] loss: 0.115\n",
      "[Epoch 3, Batch 600] loss: 0.129\n",
      "[Epoch 3, Batch 700] loss: 0.123\n",
      "[Epoch 3, Batch 800] loss: 0.125\n",
      "[Epoch 3, Batch 900] loss: 0.114\n",
      "[Epoch 4, Batch 100] loss: 0.107\n",
      "[Epoch 4, Batch 200] loss: 0.103\n",
      "[Epoch 4, Batch 300] loss: 0.094\n",
      "[Epoch 4, Batch 400] loss: 0.093\n",
      "[Epoch 4, Batch 500] loss: 0.106\n",
      "[Epoch 4, Batch 600] loss: 0.095\n",
      "[Epoch 4, Batch 700] loss: 0.099\n",
      "[Epoch 4, Batch 800] loss: 0.111\n",
      "[Epoch 4, Batch 900] loss: 0.112\n",
      "[Epoch 5, Batch 100] loss: 0.100\n",
      "[Epoch 5, Batch 200] loss: 0.065\n",
      "[Epoch 5, Batch 300] loss: 0.084\n",
      "[Epoch 5, Batch 400] loss: 0.084\n",
      "[Epoch 5, Batch 500] loss: 0.089\n",
      "[Epoch 5, Batch 600] loss: 0.092\n",
      "[Epoch 5, Batch 700] loss: 0.098\n",
      "[Epoch 5, Batch 800] loss: 0.080\n",
      "[Epoch 5, Batch 900] loss: 0.097\n",
      "[Epoch 6, Batch 100] loss: 0.075\n",
      "[Epoch 6, Batch 200] loss: 0.072\n",
      "[Epoch 6, Batch 300] loss: 0.073\n",
      "[Epoch 6, Batch 400] loss: 0.069\n",
      "[Epoch 6, Batch 500] loss: 0.080\n",
      "[Epoch 6, Batch 600] loss: 0.077\n",
      "[Epoch 6, Batch 700] loss: 0.076\n",
      "[Epoch 6, Batch 800] loss: 0.080\n",
      "[Epoch 6, Batch 900] loss: 0.073\n",
      "[Epoch 7, Batch 100] loss: 0.066\n",
      "[Epoch 7, Batch 200] loss: 0.070\n",
      "[Epoch 7, Batch 300] loss: 0.058\n",
      "[Epoch 7, Batch 400] loss: 0.054\n",
      "[Epoch 7, Batch 500] loss: 0.075\n",
      "[Epoch 7, Batch 600] loss: 0.065\n",
      "[Epoch 7, Batch 700] loss: 0.071\n",
      "[Epoch 7, Batch 800] loss: 0.067\n",
      "[Epoch 7, Batch 900] loss: 0.069\n",
      "[Epoch 8, Batch 100] loss: 0.051\n",
      "[Epoch 8, Batch 200] loss: 0.055\n",
      "[Epoch 8, Batch 300] loss: 0.058\n",
      "[Epoch 8, Batch 400] loss: 0.066\n",
      "[Epoch 8, Batch 500] loss: 0.053\n",
      "[Epoch 8, Batch 600] loss: 0.054\n",
      "[Epoch 8, Batch 700] loss: 0.061\n",
      "[Epoch 8, Batch 800] loss: 0.065\n",
      "[Epoch 8, Batch 900] loss: 0.053\n",
      "[Epoch 9, Batch 100] loss: 0.048\n",
      "[Epoch 9, Batch 200] loss: 0.061\n",
      "[Epoch 9, Batch 300] loss: 0.050\n",
      "[Epoch 9, Batch 400] loss: 0.043\n",
      "[Epoch 9, Batch 500] loss: 0.052\n",
      "[Epoch 9, Batch 600] loss: 0.054\n",
      "[Epoch 9, Batch 700] loss: 0.053\n",
      "[Epoch 9, Batch 800] loss: 0.058\n",
      "[Epoch 9, Batch 900] loss: 0.048\n",
      "[Epoch 10, Batch 100] loss: 0.041\n",
      "[Epoch 10, Batch 200] loss: 0.038\n",
      "[Epoch 10, Batch 300] loss: 0.038\n",
      "[Epoch 10, Batch 400] loss: 0.046\n",
      "[Epoch 10, Batch 500] loss: 0.046\n",
      "[Epoch 10, Batch 600] loss: 0.050\n",
      "[Epoch 10, Batch 700] loss: 0.049\n",
      "[Epoch 10, Batch 800] loss: 0.056\n",
      "[Epoch 10, Batch 900] loss: 0.049\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "model = SimpleANN()\n",
    "\n",
    "# 손실함수 최적화 알고리즘 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# 모델 학습\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        # 기울기 초기화, no_grad 평가단계에서 오차함수를 줄이는 방향으로 업데이트 하기 위해서 미분을 하는데 즉,기울기 계산하지않는다\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순전파 + 역전파 + 최적화\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 손실 출력\n",
    "        running_loss = running_loss + loss.item()\n",
    "        if i%100 == 99:\n",
    "            print(f\"[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}\")\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85e3ac1f-0021-4a49-91ee-d78a78d559df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 97.35%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total = total+labels.size(0)\n",
    "        correct = correct + (predicted == labels).sum().item()\n",
    "        # print(images, labels)\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb09bd2-1dc8-40d2-9e0e-a7ff22a95e25",
   "metadata": {},
   "source": [
    "배운내용\n",
    "학습을 위해 손실 함수, 모델 정의, 역전파 사용, 가중치 업데이트, 데이터 쪼개는 방법 \n",
    "\n",
    "손실함수 - 예측값, 실제값의 차이, DL이 학습이 잘되는 형태로 구성, 단순히 오차만 계산하는것이 아니고 오차가 어떻게 학습이 잘되는 형태인지 나타낸다. 모델의 성능을 평가 가능."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
